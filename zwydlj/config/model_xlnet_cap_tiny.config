[train] #train parameters
epoch = 10
batch_size = 1
shuffle = True
reader_num = 0
optimizer = adam
learning_rate = 2e-5
step_size = 1
lr_multiplier =  0.9995
gradient_accumulation_steps=3
max_grad_norm=1e-4

[eval] #eval parameters
batch_size = 1
shuffle = False
reader_num = 0

[data]
train_dataset_type=JsonListFromFiles
train_formatter_type=XLNetWordFormatter
train_data_path=data
train_file_list=train_train.json

valid_dataset_type=JsonListFromFiles
valid_formatter_type=XLNetWordFormatter
valid_data_path=data
valid_file_list=train_val.json

test_dataset_type=JsonListFromFiles
test_formatter_type=XLNetWordFormatter
test_data_path=data
test_file_list=validation.json

max_question_len = 1536
max_option_len = 64
word2id = data/word2id.txt

[model]
model_name = ModelLC
bert_path = ../xlnet_tiny
max_seq_len = 512
dropout = 0.1
hidden_size = 768
magic_param = 36736
bi_direction = True
num_layers = 2

[output]
output_time=1
test_time=1
model_path=output/modelcap
model_name=bert
tensorboard_path=output/bertcap/tensorboard

accuracy_method=SingleLabelTop1
output_function=Basic
output_value=micro_precision
